from cmath import sqrt
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error


def plot_precision_recall(*args):
    plt.clf()
    max_x = 0.0000001
    max_y = 0.0000001
    for i in range(len(args)):
        if  i % 3 == 0:
            recall_list = args[i]
            precision_list = args[i + 1]
            label = args[i + 2]
            x_max = recall_list[np.array(recall_list).argsort()[-1]]
            y_max = precision_list[np.array(precision_list).argsort()[-1]]
            if x_max > max_x:
                max_x = x_max
            if y_max > max_y:
                max_y = y_max
            plt.plot(recall_list, precision_list, label=label)

    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.xlim([0.0, max_x*1.5])
    plt.ylim([0.0, max_y*1.5])
    plt.legend(loc='upper right')
    plt.title('Precision-Recall curve')
    plt.show()



# Method to calculate the precision and recall measures
def calculate_precision_recall(data_model, training_dict, test_dict, top=10):
    # Create cutoff list for precision and recall calculation
    cutoff_list = list(range(1, top + 1))

    ism_avg_precision_list = []
    ism_avg_recall_list = []

    num_test_users_sample = len(data_model.test_users)

    for N in cutoff_list:
        ism_sum_precision = 0
        ism_sum_recall = 0
        ok = 0
        for user_id in data_model.test_users:
            if user_id in training_dict.keys():

                ism_hitset = test_dict[user_id].intersection(set(training_dict[user_id][0:N]))
                testset = test_dict[user_id]
                # print("user_id: " + str(ok))
                # print("hit: " + str(len(ism_hitset)))
                # print("testset:" + str(len(testset)))
                # print("N: " + str(N))
                # print("ism_sum_precision:" + str(ism_sum_precision))
                # print("ism_sum_recall:" + str(ism_sum_recall))
                # print("#############################")
                ism_sum_precision += float(len(ism_hitset)) / float(len(testset))
                ism_sum_recall += float(len(ism_hitset)) / float(N)
            ok += 1
        ism_avg_precision = ism_sum_precision / float(num_test_users_sample)
        ism_avg_recall = ism_sum_recall / float(num_test_users_sample)

        ism_avg_precision_list.append(ism_avg_precision)
        ism_avg_recall_list.append(ism_avg_recall)
    # print("ism_avg_precision_list")
    # print(ism_avg_precision_list)
    # print("ism_avg_recall_list")
    # print(ism_avg_recall_list)
    return ism_avg_recall_list, ism_avg_precision_list

def rmse(prediction, ground_truth):
    prediction = prediction[ground_truth.nonzero()].flatten()
    ground_truth = ground_truth[ground_truth.nonzero()].flatten()
    return sqrt(mean_squared_error(prediction, ground_truth))

# ism_avg_precision_list =[0.0004098360655737705, 0.0004564083457526081, 0.0004564083457526081, 0.0004564083457526081, 0.0004564083457526081, 0.0004564083457526081, 0.0004564083457526081, 0.0004564083457526081, 0.0004564083457526081, 0.0004564083457526081, 0.0004564083457526081, 0.0004564083457526081, 0.0008127875332080607, 0.0008127875332080607, 0.0008127875332080607, 0.0008127875332080607, 0.0008127875332080607, 0.0008127875332080607, 0.0008127875332080607, 0.0008127875332080607, 0.0008127875332080607, 0.0008127875332080607, 0.0008127875332080607, 0.0008127875332080607, 0.0008127875332080607, 0.0008127875332080607, 0.0008593598133868983, 0.0008593598133868983, 0.0009605539036520267, 0.0009605539036520267, 0.0009605539036520267, 0.005058914559389731, 0.005058914559389731, 0.005644394653066547, 0.005644394653066547, 0.005690966933245384, 0.005690966933245384, 0.005690966933245384, 0.005690966933245384, 0.008267079345423369, 0.008267079345423369, 0.008267079345423369, 0.008267079345423369, 0.008267079345423369, 0.008267079345423369, 0.008267079345423369, 0.008267079345423369, 0.00863965758685407, 0.008686229867032907, 0.008686229867032907]
# ism_avg_recall_list = [0.00819672131147541, 0.00819672131147541, 0.00546448087431694, 0.004098360655737705, 0.003278688524590164, 0.00273224043715847, 0.00234192037470726, 0.0020491803278688526, 0.0018214936247723133, 0.001639344262295082, 0.0014903129657228018, 0.001366120218579235, 0.0018915510718789407, 0.001756440281030445, 0.001639344262295082, 0.0015368852459016393, 0.001446480231436837, 0.001366120218579235, 0.0012942191544434857, 0.0012295081967213116, 0.00117096018735363, 0.0011177347242921013, 0.0010691375623663579, 0.0010245901639344263, 0.0009836065573770492, 0.0009457755359394704, 0.001214329083181542, 0.00117096018735363, 0.0014132278123233466, 0.001366120218579235, 0.0013220518244315177, 0.0015368852459016393, 0.0014903129657228018, 0.0016875602700096434, 0.001639344262295082, 0.0018214936247723137, 0.0017722640673460347, 0.0017256255392579809, 0.0016813787305590582, 0.0022540983606557374, 0.002199120351859256, 0.0021467603434816547, 0.0020968356843309183, 0.002049180327868853, 0.0020036429872495446, 0.001960085531004989, 0.0019183815835367981, 0.0020491803278688526, 0.0021746403479424555, 0.0021311475409836063]
#
# a = [0.0, 0.00010119409026512851, 0.002150374418133981, 0.002150374418133981, 0.002150374418133981, 0.0030611212305201377, 0.0032088876009641037, 0.004965327881994549, 0.004965327881994549, 0.004965327881994549, 0.00512295713798446, 0.005224151228249589, 0.005224151228249589, 0.005224151228249589, 0.005770599315681283, 0.005770599315681283, 0.005770599315681283, 0.005928228571671194, 0.005928228571671194, 0.005928228571671194, 0.005928228571671194, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.00684492617596993, 0.00684492617596993, 0.00684492617596993, 0.00684492617596993, 0.00684492617596993]
# b = [0.0, 0.004098360655737705, 0.00546448087431694, 0.004098360655737705, 0.003278688524590164, 0.004098360655737705, 0.0058548009367681494, 0.007172131147540984, 0.006375227686703098, 0.005737704918032787, 0.005961251862891208, 0.006147540983606557, 0.005674653215636822, 0.005269320843091334, 0.00546448087431694, 0.005122950819672131, 0.0048216007714561235, 0.005009107468123862, 0.004745470232959448, 0.004508196721311476, 0.0042935206869633095, 0.004470938897168405, 0.004276550249465431, 0.004098360655737706, 0.003934426229508196, 0.0037831021437578806, 0.0036429872495446266, 0.0035128805620608895, 0.003391746749576032, 0.0032786885245901635, 0.0031729243786356416, 0.0030737704918032786, 0.0029806259314456027, 0.0028929604628736743, 0.0028103044496487124, 0.0027322404371584704, 0.002658396101019052, 0.0025884383088869713, 0.0025220680958385876, 0.002459016393442623, 0.002399040383846462, 0.00234192037470726, 0.0022874571101791836, 0.0022354694485842027, 0.002185792349726776, 0.002672843905915894, 0.0026159748866410874, 0.002561475409836065, 0.0025092004014720644, 0.0024590163934426227]
#
# plot_precision_recall(ism_avg_recall_list, ism_avg_precision_list, "item_similarity_model",a,b,"dd")

# a = [0.0, 0.00010119409026512851, 0.002150374418133981, 0.002150374418133981, 0.002150374418133981, 0.0030611212305201377, 0.0032088876009641037, 0.004965327881994549, 0.004965327881994549, 0.004965327881994549, 0.00512295713798446, 0.005224151228249589, 0.005224151228249589, 0.005224151228249589, 0.005770599315681283, 0.005770599315681283, 0.005770599315681283, 0.005928228571671194, 0.005928228571671194, 0.005928228571671194, 0.005928228571671194, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.006074598595090398, 0.00684492617596993, 0.00684492617596993, 0.00684492617596993, 0.00684492617596993, 0.00684492617596993]
# b = [0.0, 0.004098360655737705, 0.00546448087431694, 0.004098360655737705, 0.003278688524590164, 0.004098360655737705, 0.0058548009367681494, 0.007172131147540984, 0.006375227686703098, 0.005737704918032787, 0.005961251862891208, 0.006147540983606557, 0.005674653215636822, 0.005269320843091334, 0.00546448087431694, 0.005122950819672131, 0.0048216007714561235, 0.005009107468123862, 0.004745470232959448, 0.004508196721311476, 0.0042935206869633095, 0.004470938897168405, 0.004276550249465431, 0.004098360655737706, 0.003934426229508196, 0.0037831021437578806, 0.0036429872495446266, 0.0035128805620608895, 0.003391746749576032, 0.0032786885245901635, 0.0031729243786356416, 0.0030737704918032786, 0.0029806259314456027, 0.0028929604628736743, 0.0028103044496487124, 0.0027322404371584704, 0.002658396101019052, 0.0025884383088869713, 0.0025220680958385876, 0.002459016393442623, 0.002399040383846462, 0.00234192037470726, 0.0022874571101791836, 0.0022354694485842027, 0.002185792349726776, 0.002672843905915894, 0.0026159748866410874, 0.002561475409836065, 0.0025092004014720644, 0.0024590163934426227]
#
# plt.clf()
# q = plt.plot(ism_avg_precision_list, ism_avg_recall_list, label='a')
# e = plt.plot(a, b, label='b')
# plt.xlabel('Recall')
# plt.ylabel('Precision')
# plt.ylim([0.0, 0.02])
# plt.xlim([0.0, 0.02])
# plt.title('Precision-Recall curve')
# # pl.legend([q, e], ('red line', 'b'))# make legend
# plt.legend(loc='upper right')
# # pl.legend([q, e], ('red line', 'b'), loc=9, bbox_to_anchor=(0.5, -0.2))
# plt.show()
#
#


















# pl.clf()
# pl.plot(ism_avg_precision_list, ism_avg_recall_list, 'r', label= "a")
# pl.plot(a, b, 'b', label="b")
# pl.xlabel('Recall')
# pl.ylabel('Precision')
# pl.ylim([0.0, 0.075])
# pl.xlim([0.0, 0.075])
#
# pl.title('Precision-Recall curve')
# pl.legend(loc=9, bbox_to_anchor=(0.5, -0.2))
# pl.show()
